---
title: "Project"
subtitle: "Creating Value Through Data Mining"
author: "Malou-Tinette Kouango & Veronica Rowe"
date: "`r Sys.Date()`"
output: html_document
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project Stroke Prediction Dataset 
# Clearing the console
```{r, warning = F,message = F, echo = TRUE}
#clear all the console
list=ls()
rm(list=ls()) 
cat("\014")
ls()
```

#Reading the Stroke dataset
```{r}
Stroke <- read.csv(file.choose())
```

# Loading the relevant packages
```{r, warning=FALSE}
library(ggplot2) 
library(FNN)
library(dummies)
library(e1071)
library (caret)
library(reshape2)
library(dplyr)
library(class)
library(naniar)
```

 
### Exposing the data structure
```{r}
# Types of variables:
str(Stroke)
```

### We have 12 variables in the Stroke dataset. We have different type of data. Our outcome variable "Stroke" is a binary outcome, taking value 1 if the person had a stroke and 0 if they haven't had a stroke. 
### Bmi is seen as a character because of the N/A => we must change N/A strings to real NA in R, and set the variable as numeric to be able to visualize it in our exploratory graphs.
### The variables gender, ever_married, work_type, Residence_type and smoking status are seen as character, when they are categorical => we already change them to factor for better data visualization.

```{r}
# Changing N/A characters in bmi to real NA:
Stroke = replace_with_na(Stroke, replace = list(bmi = "N/A")) # bmi has NA now
# Change bmi from character to numerical variable:
Stroke$bmi <- as.numeric(Stroke$bmi)

# Change character variables as categorical (factor)
Stroke[,c(2,6:8,11)] <- lapply(Stroke[,c(2,6:8,11)], as.factor)
#str(Stroke)
```


```{r}
# Show how many different values there is for each variable
sapply(Stroke, function(x) length(unique(x)))
summary(Stroke)
```
#### Using sapply function from TP1 to find out more about the variables. We realise that in gender, there is only one observation as categorised as "Other". To simplify our analysis, we will later disregard the row with that observation, as it not significant enough to be taken into consideration (1/5110 = 0.01956947%) (row/observation number id = 56'156/ row = 3117). We will also disregard the ID column as it only represent the patient id in the hospital and thus has no impact on our outcome variable of interest Stroke.

## Finding out information on our outcome variable
```{r}
table(Stroke$stroke)
```
#### We see that 249 people had a stroke and 4861 did not. We have an unbalanced binary outcome. 

## Visualising numerical variables. 
```{r, warning = FALSE}
quantitative_data <- (Stroke[,c(3,9)])
quantitative_data_melt <- melt(quantitative_data)
quantitative_data_means <-  quantitative_data_melt %>% group_by(variable) %>% summarise(mean.x = mean(value))
quantitative_data_median<- quantitative_data_melt %>% group_by(variable) %>% summarise(median.x = median(value))

quantitative_data_hist <- ggplot(data = quantitative_data_melt, aes(value)) + geom_histogram(fill="transparent",color = "black") + facet_wrap(~variable, scale="free", ncol = 4) + geom_vline(aes(xintercept = mean.x),quantitative_data_means, color = "blue") +  geom_vline(aes(xintercept = median.x),quantitative_data_median, color = "red")  + theme_classic() 

quantitative_data_hist
```
#### In the histograms, we see that the average age of the patient is in his 40ties and the average glucose is right-skewed.


#### Boxplot visualisation
```{r}
par(mfrow = c(2, 3))
boxplot(id~hypertension,data = Stroke, main = "Hypertension distribution")
boxplot(id~heart_disease,data = Stroke,  main = "Heart disease distribution")
boxplot(id~ever_married,data = Stroke,  main = "Marriage status distribution")
boxplot(id~work_type,data = Stroke,  main = "Work Type distribution")
boxplot(id~Residence_type,data = Stroke,  main = "Residence type distribution")
boxplot(id~smoking_status,data = Stroke,  main = "Smoking status distribution")
boxplot(id~stroke,data = Stroke,  main = "Stroke distribution")
```
#### We see that most variables are evenly distributed, roughly same weights ("50% of the sample have the account and the other 50% have not, for the variables separated into 2 categories"). We see that there is a slight majority of people not accepting the Personal Loan (mean of 0 is higher than the one of 1). I am skeptical of these results as above we saw that less than 10% took the Loan(PL is 1), however in the boxplot it seems like thez are nearlz on the same level.



#### Preparing for analysis : 

````{r}
# Remove only row with gender = "Other"
Stroke = Stroke[-3117,]
# Remove id row
Stroke = Stroke[,-1]
```


#### Transforming the categorical variables with more than 2 categories into dummy variables (Here it concerns variables work_type (6) & smoking_status (10))

```{r}
set.seed(1)
# Put work_type as dummy:
work_type_Dummies <- cbind( Stroke[1:5], dummy(Stroke$work_type, sep = "_"), Stroke[7:11])
names(work_type_Dummies)[6:10] <- c("children","Govt_job", "Never_Worked", "Private", "Self-employed")
work_type_Dummies
Stroke <- work_type_Dummies
```

```{r}
# Put smoking_status as dummy:
smoking_status_Dummies <- cbind( Stroke[1:13], dummy(Stroke$smoking_status, sep = "_"), Stroke[15])
names(smoking_status_Dummies)[14:17] <- c("formerly_smoked", "never_smoked", "smokes", "unknown")
smoking_status_Dummies
Stroke <- smoking_status_Dummies
```


#### Partitioning the 2 groups (60% in Training, 40% in Valid) & normalizing the data 
```{r}
Train <- sample(row.names(Stroke), 0.6*dim(Stroke)[1])
Valid <- setdiff(row.names(Stroke), Train)
Train <- Stroke[Train, ]
Valid <- Stroke[Valid, ]
dim(Train)
dim(Valid)
# The data has been correctly partitioned into 60% (3'065 obs) in T and 40% in V (2'044 obs)
```


#### Initializing training, validation data, using preProcess()
```{r}
# initialize normalized training and validation sets:
Train_norm <- Train
Valid_norm <- Valid
Stroke_normalized <- Stroke

# use preProcess() from the caret package to normalize the variables age, average_glucose and bmi:
Value.norm <- preProcess(Train[, c(2,12,13)], method= "range")

Train_norm[, c(2,12,13)] <- predict(Value.norm, Train[, c(2,12,13)])
Valid_norm[, c(2,12,13)] <- predict(Value.norm, Valid[, c(2,12,13)])
Stroke_normalized[, c(2,12,13)] <- predict(Value.norm, Stroke[, c(2,12,13)])
```

########################################################
### Table of Validation group & k equal 1.
```{r}
table(Valid_norm$Personal.Loan,predictive_knn_1)
```
#### We see that in the validation data, there are 147 customers are predicted and actually take out the Personal loan. The majority will not take the Loan offer (True negatives are 1765). There are 58 false negatives (the prediction predicts that they won't take a Loan but they do, 58/2000 is 2.9%) , and 30 false positives (the prediction says that they will take a Loan but they don't, 30/2000 isb 1.5%). The confusion matrix below, lets us see more in detail the specificity, accuracy, sensitivity values.

## Creating the Confusion Matrix for the customers in general
```{r}
caret::confusionMatrix(data = predictive_knn_1, as.factor(Valid_norm$Personal.Loan), positive = "1")
```
#### We see that there is a small p-value that is a good sign. Moreover, the accuracy is not bad as it is of 0.956. We know that the probability of being classified correctly is 95.6%. This is a reliable knn prediction with k value 1. We have only seen the notions of sensitivity and specificity. We see that the specificity value is quite high (98.33%) meaning that C1 is nearly always well classified, however the classification of C0 is not so performant (sensitivity is 71.71%). The best is using specificity. 

## b. Choice of k

```{r}

# initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 14, 1), accuracy = rep(0, 14))
# compute knn for different k on validation.
for(i in 1:14) {
knn.pred <- knn(train = Train_norm[, -c(1,5,10)], test = Valid_norm[, -c(1,5,10)],
cl = Train_norm$Personal.Loan, k = i)
accuracy.df[i, 2] <- confusionMatrix(knn.pred, positive = "1", Valid_norm[, 3])$overall[1]}
head(accuracy.df)
```


















```{r}

ctrl_acc = trainControl(method = "cv",
                    number = 10,)
set.seed(1)
knnfit_acc = train(Personal.Loan ~ ., 
               data = Train_norm,
               method = "knn",
               trControl = ctrl_acc,
               tuneGrid = expand.grid(k = seq(50)),
               )
plot(knnfit_acc, main = "Accuracy vs K values", ylab = "Accuracy (CV)")
```



## c. Confusion matrix for the validation data 
```{r}

predictive_knn_2  = FNN::knn(train = Train_norm[,-c(10)], 
                           cl = Train_norm$Personal.Loan, 
                           test = Valid_norm[,-10], k = ?, prob = T)


caret::confusionMatrix(data = predictive_knn_2, as.factor(Valid_norm$Personal.Loan), positive = "1")






```


## d. Another Customer
```{r}

Customer_2 <- data.frame(40,10,84,2,2,0,1,0,0,0,0,1,1)
names(Customer_2)<- names(UB2)[-10]
Customer_2
```

## e. Creating & Comparing the confusion matrix 
#### Separating the 3 categories
```{r}
set.seed(1)
Train_50 <- sample(rownames(UB2), dim(UB2)[1]*0.5)
Valid_30 <- sample(setdiff(rownames(UB2), Train_50), dim(UB2)[1]*0.3)
Test_20 <- setdiff(rownames(UB2), union(Train_50, Valid_30))
```
#Creaating the data 
```{r}                           
Train_50_final <- UB2[Train_50,]
Valid_30_final <- UB2[Valid_30,]
Test_20_final <- UB2[Test_20,]
```

```{r}
# initialize normalized training, validation data, complete data frames to originals
Train_50norm <- Train_50_final
Valid_30norm <- Valid_30_final
Test_20norm <- Test_20_final
UB_norm <- UB2
# use preProcess() from the caret package to normalize the variables.
Value.norm.point.e <- preProcess(Train_50_final[, c(1,2,3,5,9)], method= "range")

Train_50norm [, c(1,2,3,5,9)] <- predict(Value.norm.point.e, Train_50_final[, c(1,2,3,5,9)])
Valid_30norm[, c(1,2,3,5,9)] <- predict(Value.norm.point.e, Valid_30_final[, c(1,2,3,5,9)])
Test_20norm [, c(1,2,3,5,9)] <- predict(Value.norm.point.e, Test_20_final[, c(1,2,3,5,9)])
UB_norm[, c(1,2,3,5,9)] <- predict(Value.norm.point.e, UB2[, c(1,2,3,5,9)])
New_norm.e <- predict(Value.norm.point.e, Customer_2)
```

## Testing the model with supposition that knn is equal to 1 on the Customer
```{r}
Train_50norm$Personal.Loan = as.factor(Train_50norm$Personal.Loan)

Customer_2_with_best_knn = FNN::knn(train = Train_50norm[,-10], 
                      cl = Train_50norm$Personal.Loan,
                      test = New_norm.e, k = 1, prob = T)

Customer_2_with_best_knn 
```

## Creating the Confusion Matrix for the customers in general
```{r}
caret::confusionMatrix(data = Customer_2_with_best_knn, as.factor(Valid30_norm$Personal.Loan), positive = "1")